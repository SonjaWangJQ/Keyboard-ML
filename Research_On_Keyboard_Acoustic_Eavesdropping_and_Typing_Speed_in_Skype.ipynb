{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1z9lzY2WeNC3vp4c47yMhRvUBBSsm_qdG",
      "authorship_tag": "ABX9TyOs0fVzS4bGQjgclJK6p/k9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SonjaWangJQ/Keyboard-ML/blob/main/Research_On_Keyboard_Acoustic_Eavesdropping_and_Typing_Speed_in_Skype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The audio data was recorded and saved in WAV format with the following specifications:\n",
        "\n",
        "Sampling Frequency: 44.1kHz\n",
        "Bit Depth: 32-bit PCM\n",
        "Audio Channel: Mono"
      ],
      "metadata": {
        "id": "eCB7qwC9S5sJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# turn mp4 into wav and sr = 44100\n",
        "!pip3 install pydub\n",
        "from pydub import AudioSegment\n",
        "def mp4_to_wav(audio_file, output_file,target_sr = 16000):\n",
        "  mp4_file1 = AudioSegment.from_file(audio_file, \"mp4\")\n",
        "  wav_file1 = mp4_file1.export(output_file, format=\"wav\")\n",
        "  y, sr = librosa.load(wav_file1)\n",
        "\n",
        "  y_resampled = librosa.resample(y, orig_sr=sr, target_sr = target_sr)\n",
        "\n",
        "  sf.write(output_file, y_resampled, samplerate= target_sr)\n"
      ],
      "metadata": {
        "id": "4BX1irxrEBSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# keep audio as mono signal\n",
        "\n",
        "def wav_read(audio_file):\n",
        "    \"\"\"Return 1D NumPy array of wave-formatted audio data denoted by filename.\n",
        "\n",
        "    Input should be a string containing the path to a wave-formatted audio file.\n",
        "    \"\"\"\n",
        "    sample_rate, signal = wav.read(audio_file)\n",
        "    print('SAMPLE_RATE:',sample_rate)\n",
        "    if type(signal[0]) == np.ndarray:\n",
        "        return signal[:, 0]\n",
        "    else:\n",
        "        return signal\n"
      ],
      "metadata": {
        "id": "X3bX_XGZn7Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Proprocessing:\n",
        "1. noise removal\n",
        "2. keystrokes segmentation"
      ],
      "metadata": {
        "id": "zFMK_ijAZgSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def frequency_filter(audio_file, output_file, sample_rate, low_freq, high_freq):\n",
        "    \"\"\"\n",
        "    Filter out frequencies outside the specified range [low_freq, high_freq].\n",
        "\n",
        "    Parameters:\n",
        "        signal (np.ndarray): Input signal in the time domain.\n",
        "        sample_rate (int): Sampling rate of the signal in Hz.\n",
        "        low_freq (int): Lower cutoff frequency in Hz. Frequencies below this value will be removed.\n",
        "        high_freq (int): Upper cutoff frequency in Hz. Frequencies above this value will be removed.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Filtered signal in the time domain.\n",
        "    \"\"\"\n",
        "    signal = wav_read(audio_file)\n",
        "    n = len(signal)\n",
        "    freqs = np.fft.fftfreq(n, 1 / sample_rate)\n",
        "    fft_signal = np.fft.fft(signal)\n",
        "\n",
        "    # Find the indices of frequencies outside the specified range\n",
        "    low_index = np.argmin(np.abs(freqs - low_freq))\n",
        "    high_index = np.argmin(np.abs(freqs - high_freq))\n",
        "\n",
        "    # Set frequencies outside the range to zero\n",
        "    fft_signal[:low_index] = 0\n",
        "    fft_signal[high_index:] = 0\n",
        "\n",
        "    # Apply inverse FFT to obtain the filtered signal in time domain\n",
        "    # filtered_signal = np.fft.ifft(fft_signal)\n",
        "    filtered_signal = np.fft.ifft(fft_signal)\n",
        "\n",
        "    # Take the real part of the filtered signal (ignore imaginary parts due to numerical errors)\n",
        "    filtered_signal = np.real(filtered_signal)\n",
        "    wav.write(output_file, sample_rate, filtered_signal.astype(np.int16))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ker0-Xier8mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### abs(signal)\n",
        "def calculate_energy(signal):\n",
        "    return abs(signal)\n",
        "def calculate_A_energy(signal,sample_rate,window_size = 10):\n",
        "\n",
        "    energy = calculate_energy(signal)\n",
        "    A_energy2 = np.zeros(len(signal))\n",
        "\n",
        "    for i in range(len(signal) - window_size + 1):\n",
        "        A_energy2[i] = np.sum(energy[i:i+window_size])\n",
        "\n",
        "    return A_energy2\n",
        "\n",
        "\n",
        "def A_t(signal,sample_rate,t): # t = 0.1\n",
        "  W = int(sample_rate* t)\n",
        "  print('A_t_Winowsize:',W)\n",
        "  A_energy = calculate_A_energy(signal,sample_rate = 44100,window_size = 10)\n",
        "  print('Max of Amptitude:',max(A_energy))\n",
        "\n",
        "  A_t = []\n",
        "  n = 0\n",
        "  if max(A_energy) <= 10000:\n",
        "    # threshold = 1000\n",
        "    threshold = 0.2 * int(max(A_energy))\n",
        "    while n <= (len(signal) - W + 1) :\n",
        "      if (A_energy[n]) >= threshold and (A_energy[n] >= max(A_energy[n: n+W])):\n",
        "        # A_t.append([n,A_energy[n]])\n",
        "        A_t.append(n)\n",
        "        n += W\n",
        "      else:\n",
        "        n += 1\n",
        "\n",
        "  else:\n",
        "    # threshold = 2000\n",
        "    threshold = 0.5 * int(max(A_energy))\n",
        "    while n <= (len(signal) - W + 1) :\n",
        "      if (A_energy[n]) >= threshold and (A_energy[n] >= max(A_energy[n: n+W])):\n",
        "        # A_t.append([n,A_energy[n]])\n",
        "        A_t.append(n)\n",
        "        n += W\n",
        "      else:\n",
        "        n += 1\n",
        "  return A_t\n",
        "\n"
      ],
      "metadata": {
        "id": "79koXrrtn7XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def keystrokes(audio_file,t,sample_rate =44100):\n",
        "    signal = wav_read(audio_file)\n",
        "    A_energy = calculate_A_energy(signal,sample_rate ,window_size = 10)\n",
        "    # At =   A_t(signal,threshold,t,sample_rate= 44100)\n",
        "    At = A_t(signal,sample_rate,t)\n",
        "    a = int(0.2*t* sample_rate)\n",
        "    b = int(0.8*t* sample_rate)\n",
        "    # print(a,b)\n",
        "\n",
        "    keystrokes = []\n",
        "\n",
        "\n",
        "    for i in At:\n",
        "\n",
        "      if (i+b)<= len(signal):\n",
        "        keystroke = signal[i-a: i+b]\n",
        "        keystrokes.append(keystroke)\n",
        "        # print(i)\n",
        "      if (i + b) > len(signal):\n",
        "        keystroke = signal[i-a :]\n",
        "        keystrokes.append(keystroke)\n",
        "        # print(i)\n",
        "\n",
        "    return np.array(keystrokes)\n",
        "    # print(len(keystrokes))"
      ],
      "metadata": {
        "id": "tUuvVyWh4HLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data Augmentation pipelime\n",
        "2. Feature Extraction pipeline\n"
      ],
      "metadata": {
        "id": "zhFZjK_hZ-B2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiWvjS7hZm5q"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class AudioUtil():\n",
        "  # ----------------------------\n",
        "  # Load an audio file. Return the signal as a tensor and the sample rate\n",
        "  # ----------------------------\n",
        "\n",
        "  @staticmethod\n",
        "  def open(audio_file):\n",
        "    sig, sr = torchaudio.load(audio_file)\n",
        "    return (sig, sr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # time shift\n",
        "\n",
        "  @staticmethod\n",
        "  def time_shift(aud, shift_limit):\n",
        "    sig,sr = aud\n",
        "    _, sig_len = sig.shape\n",
        "    shift_amt = int(random.random() * shift_limit * sig_len)\n",
        "    return (sig.roll(shift_amt), sr)\n",
        "\n",
        "  # amplity all timedata\n",
        "  @staticmethod\n",
        "  def time_Amp(aud, Amp_size):\n",
        "    sig,sr = aud\n",
        "    Amp_sig = sig * Amp_size\n",
        "    return (Amp_sig , sr)\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def compute_mfcc(aud, n_mfcc=32, window_size=0.01, step_size=0.0025, n_filters=32):\n",
        "\n",
        "            sig, sr = aud\n",
        "            n_fft = int(sr * window_size)\n",
        "            hop_length = int(sr * step_size)\n",
        "\n",
        "            mfccs = librosa.feature.mfcc(\n",
        "                y=sig.numpy(),\n",
        "                sr=sr,\n",
        "                n_mfcc=n_mfcc,\n",
        "                n_fft=n_fft,\n",
        "                hop_length=hop_length,\n",
        "                n_mels=n_filters\n",
        "            )\n",
        "            return mfccs.T\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def compute_stft(aud, n_fft=2048, hop_length=512, window='hann'):\n",
        "    sig, sr = aud\n",
        "    audio = sig.squeeze().numpy()\n",
        "\n",
        "    # Compute STFT\n",
        "    stft_result = librosa.core.stft(audio, n_fft=2048, hop_length=512, window='hann')\n",
        "\n",
        "    # Get magnitude spectrum\n",
        "    magnitude = np.abs(stft_result)\n",
        "\n",
        "    # Get frequency axis\n",
        "    freqs = librosa.core.fft_frequencies(sr=sr, n_fft=2048)\n",
        "\n",
        "    return freqs, magnitude\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load data"
      ],
      "metadata": {
        "id": "FAA1jZ9LdryZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buLRPmQof9G5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# SoundDS1 no ampf\n",
        "# ----------------------------\n",
        "class SoundDS(Dataset):\n",
        "\n",
        "  def __init__(self, csv_filename):\n",
        "    self.csv_filename = csv_filename\n",
        "    self.sr = 44100\n",
        "    self.channel = 1\n",
        "    # self.shift_pct = -0.01   # +10ms\n",
        "    self.audio_file, self.class_id = self.load_datapath()\n",
        "\n",
        "\n",
        "  def load_datapath(self):\n",
        "        audio_file, class_id = [], []\n",
        "        with open(self.csv_filename) as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)  # Skip the header line\n",
        "            for row in reader:\n",
        "                i, l = row\n",
        "                audio_file.append(i)\n",
        "                class_id.append(int(l))  # Convert class ID to integer\n",
        "        return audio_file, class_id\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.audio_file)\n",
        "\n",
        "\n",
        "  def get_class_counts(self):\n",
        "        class_counts = {}\n",
        "        for cls_id in self.class_id:\n",
        "            if cls_id in class_counts:\n",
        "                class_counts[cls_id] += 1\n",
        "            else:\n",
        "                class_counts[cls_id] = 1\n",
        "        return class_counts\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    # Absolute file path of the audio file - concatenate the audio directory with\n",
        "    # the relative path，Get the Class ID\n",
        "\n",
        "    # Get the Class ID\n",
        "    audio_path = self.audio_file[idx]\n",
        "    class_id = self.class_id[idx]\n",
        "\n",
        "\n",
        "    aud = AudioUtil.open(audio_path)\n",
        "    Amp_aud = AudioUtil.time_Amp(aud,self.amp_size)\n",
        "    mfcc_aud = AudioUtil.compute_mfcc(Amp_aud)\n",
        "    mfcc_data = np.array(mfcc_aud)\n",
        "    # fft_audio = AudioUtil.compute_fft(shift_aud )\n",
        "    # fft_data = np.array(fft_audio)\n",
        "    # return mfcc_aud, class_id\n",
        "    return mfcc_aud, class_id, audio_path # for mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Classification"
      ],
      "metadata": {
        "id": "je0F3jtEd84e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brqeYVZb-XT9"
      },
      "outputs": [],
      "source": [
        "#SVM model\n",
        "#\n",
        "# Best parameters: {'C': 10, 'kernel': 'rbf'} 0.84\n",
        "#Mfcc: aud, n_mfcc=32, window_size=0.01, step_size=0.0025, n_filters=64\n",
        "#  parameter grid for grid search\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'C': [1, 5, 10, 100],\n",
        "    # 'C': [10],\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto', 0.1, 0.01, 0.001]\n",
        "    # 'gamma':[0.001]\n",
        "    }\n",
        "\n",
        "#  SVM model\n",
        "svm = SVC()\n",
        "\n",
        "#  grid search object with 10-fold cross-validation\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=10, n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "#  best model from grid search\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict using the best model\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "target_names = [f'Class {i}' for i in range(36)]\n",
        "#   classification report\n",
        "cr = classification_report(y_test, y_pred, target_names=target_names)\n",
        "# N = 5  # Change this to the desired value\n",
        "# top_n_accuracy = top_k_accuracy_score(y_test, best_model.decision_function(X_test_scaled), k=N)\n",
        "\n",
        "\n",
        "\n",
        "N_values = [1, 2, 3, 4, 5]\n",
        "top_n_accuracies = [top_k_accuracy_score(y_test, best_model.decision_function(X_test_scaled), k=N) for N in N_values]\n",
        "\n",
        "# Print results\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Classification Report:\")\n",
        "print(cr)\n",
        "for N, accuracy in zip(N_values, top_n_accuracies):\n",
        "    print(f\"Top-{N} Accuracy Score: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Multinomial Logistic Regression  X,y 0.2 ；L2；10 fold across MFCC\n",
        "\n",
        "#X,y 0.2 ；L2；10 fold across MFCC\n",
        "\n",
        "multi_logreg = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\",max_iter=1000)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [ 1,10 ],\n",
        "    'penalty': ['l2']\n",
        "}\n",
        "\n",
        "# 10 fold across\n",
        "grid_search = GridSearchCV(multi_logreg, param_grid, cv=10, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "\n",
        "target_names = [f'Class {i}' for i in range(36)]\n",
        "\n",
        "# report\n",
        "cr = classification_report(y_test, y_pred, target_names=target_names)\n",
        "\n",
        "# Top-N accuracy score\n",
        "N_values = [1, 2, 3, 4, 5]  # You can add more N values if needed\n",
        "top_n_accuracies = [top_k_accuracy_score(y_test, best_model.predict_proba(X_test_scaled), k=N) for N in N_values]\n",
        "\n",
        "# Print top-N accuracy scores\n",
        "for N, accuracy in zip(N_values, top_n_accuracies):\n",
        "    print(f\"Top-{N} Accuracy Score: {accuracy:.4f}\")\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "HD5RlDbpJoQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random forests\n",
        "import pydot\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "from sklearn import metrics\n",
        "from openpyxl import load_workbook\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import KFold, cross_val_predict\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming you have loaded X_train_scaled, y_train, X_test_scaled, and y_test\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [ 5, 10],\n",
        "    'min_samples_leaf': [ 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Create and fit the Random Forest model using GridSearchCV\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(random_forest, param_grid, cv=10, n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "best_random_forest = grid_search.best_estimator_\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "y_test_pred_probs = cross_val_predict(best_random_forest, X_test_scaled, y_test, cv=kf, method='predict_proba')\n",
        "\n",
        "# ... (Rest of your code for calculating top-N accuracy scores and generating the classification report)\n",
        "N_values = [1, 2, 3, 4, 5]\n",
        "top_n_accuracies = []\n",
        "for N in N_values:\n",
        "    top_n_correct = 0\n",
        "    for true_label, pred_probs in zip(y_test, y_test_pred_probs):\n",
        "        top_n_indices = np.argsort(pred_probs)[::-1][:N]  # Indices of top-N classes\n",
        "        if true_label in top_n_indices:\n",
        "            top_n_correct += 1\n",
        "    top_n_accuracy = top_n_correct / len(y_test)\n",
        "    top_n_accuracies.append(top_n_accuracy)\n",
        "\n",
        "# Print the best hyperparameters found by GridSearchCV\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Print top-N accuracy scores\n",
        "for N, accuracy in zip(N_values, top_n_accuracies):\n",
        "    print(f\"Top-{N} Accuracy Score: {accuracy:.4f}\")\n",
        "\n",
        "# Generate classification report\n",
        "target_names = [f'Class {i}' for i in range(36)]\n",
        "y_test_pred = np.argmax(y_test_pred_probs, axis=1)\n",
        "cr = classification_report(y_test, y_test_pred, target_names=target_names)\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(cr)\n",
        "\n"
      ],
      "metadata": {
        "id": "V9PZvfOcTOWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation part\n",
        "one example for data shift + 10ms"
      ],
      "metadata": {
        "id": "imFALCBwfz-C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXD124mde-tc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# SoundDS +10ms\n",
        "# ----------------------------\n",
        "class SoundDS1(Dataset):\n",
        "\n",
        "  def __init__(self, csv_filename):\n",
        "    self.csv_filename = csv_filename\n",
        "\n",
        "    self.channel = 1\n",
        "    self.shift_pct = 0.01   # +10ms\n",
        "    self.audio_file, self.class_id = self.load_datapath()\n",
        "\n",
        "\n",
        "  def load_datapath(self):\n",
        "        audio_file, class_id = [], []\n",
        "        with open(self.csv_filename) as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)\n",
        "            for row in reader:\n",
        "                i, l = row\n",
        "                audio_file.append(i)\n",
        "                class_id.append(int(l))\n",
        "        return audio_file, class_id\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.audio_file)\n",
        "\n",
        "\n",
        "  def get_class_counts(self):\n",
        "        class_counts = {}\n",
        "        for cls_id in self.class_id:\n",
        "            if cls_id in class_counts:\n",
        "                class_counts[cls_id] += 1\n",
        "            else:\n",
        "                class_counts[cls_id] = 1\n",
        "        return class_counts\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    # Absolute file path of the audio file - concatenate the audio directory with\n",
        "    # the relative path，Get the Class ID\n",
        "\n",
        "    # Get the Class ID\n",
        "    audio_path = self.audio_file[idx]\n",
        "    class_id = self.class_id[idx]\n",
        "\n",
        "\n",
        "    aud = AudioUtil.open(audio_path)\n",
        "    shift_aud = AudioUtil.time_shift(aud, self.shift_pct)\n",
        "    mfcc_aud = AudioUtil.compute_mfcc(shift_aud)\n",
        "    mfcc_data = np.array(mfcc_aud)\n",
        "    # fft_audio = AudioUtil.compute_fft(shift_aud )\n",
        "    # fft_data = np.array(fft_audio)\n",
        "\n",
        "    return mfcc_aud, class_id, audio_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WiimhaWkQLt"
      },
      "outputs": [],
      "source": [
        "# shift  append into X,y\n",
        "csv_filename = \"/content/drive/MyDrive/collect_machinekeyboard/collect/piece2_441.csv\"\n",
        "sound_dataset_shift= SoundDS(csv_filename)\n",
        "X = []\n",
        "y = []\n",
        "path = []\n",
        "\n",
        "\n",
        "for idx in range(len(sound_dataset_shift)):\n",
        "    mfcc_data, class_id ,audio_path = sound_dataset_shift[idx]\n",
        "    X.append(mfcc_data)\n",
        "    y.append(class_id)\n",
        "    path.append(audio_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zAAdGH65GwU",
        "outputId": "1573920c-c804-4e11-d719-48b56cb24f4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1467, 41, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "path = np.array(path)\n",
        "# check length\n",
        "assert X.shape[0] == len(y), \"Shape mismatch between X and y\"\n",
        "assert X.shape[0] == len(path), \"Shape mismatch between X and path\"\n",
        "print(X.shape)\n",
        "num_samples, num_frames, num_coefficients, num_channels = X.shape\n",
        "MFCC_data_2d = X.reshape(num_samples, num_frames * num_coefficients)\n",
        "\n",
        "\n",
        "X_shuffled, y_shuffled,path_shuffled = shuffle(MFCC_data_2d, y, path, random_state=42)\n",
        "# X_shuffled, y_shuffled = shuffle(MFCC_data_2d, y, random_state=42)\n",
        "X_train, X_test, y_train, y_test,path_train, path_test = train_test_split(X_shuffled, y_shuffled, path_shuffled, train_size=0.8, random_state=42,stratify = y_shuffled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZLjS6hzNYub",
        "outputId": "d2b10d59-94d3-41cf-e7af-e8b35813f130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1173, 1312) (294, 1312)\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test) # keep it\n",
        "# X_val_scaled = scaler.transform(X_val)\n",
        "print(X_train_scaled.shape, X_test_scaled.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### append new data shift into trainset"
      ],
      "metadata": {
        "id": "P9pMkpKWggd5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxGM9DeB6eXt"
      },
      "outputs": [],
      "source": [
        "csv_filename = \"/content/drive/MyDrive/collect_machinekeyboard/collect/piece2_441.csv\"\n",
        "sound_dataset_shift2 = SoundDS1(csv_filename)\n",
        "X2 = []\n",
        "y2 = []\n",
        "\n",
        "for idx in range(len(sound_dataset_shift2)):\n",
        "    mfcc_data2, class_id2, audio_path = sound_dataset_shift2[idx]\n",
        "    if audio_path2 in path_train:\n",
        "        X2.append(mfcc_data2)\n",
        "        y2.append(class_id2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJzFut5eipDb",
        "outputId": "57a57953-9feb-4d50-a02b-8a3cf0e369db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2346, 1312)\n"
          ]
        }
      ],
      "source": [
        "X2 = np.array(X2)\n",
        "y2 = np.array(y2)\n",
        "\n",
        "assert X2.shape[0] == len(y2), \"Shape mismatch between X and y\"\n",
        "num_samples, num_frames, num_coefficients, num_channels = X2.shape\n",
        "\n",
        "new_X2train = X2.reshape(num_samples, num_frames * num_coefficients)\n",
        "print(new_X2train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf4801zaM-WR",
        "outputId": "2cf21c97-799a-426d-ec18-d8fe8dbd2a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2346, 1312) [11  5 15 ... 34  6 17]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X2_shuffled, y2_shuffled = shuffle( new_X2train , y2, random_state=42)\n",
        "new_X2_train_scaled = scaler.fit_transform(X2_shuffled)\n",
        "print(new_X2_train_scaled.shape, y2_shuffled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUFEBGyMPRyS"
      },
      "outputs": [],
      "source": [
        "# append X_train, y_train\n",
        "X_train_extended = np.vstack([X_train_scaled, new_X2_train_scaled])\n",
        "y_train_extended = np.concatenate([y_train, y2_shuffled])"
      ]
    }
  ]
}