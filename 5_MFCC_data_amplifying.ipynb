{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FKQzrqN7bmPb",
        "meYfx2fZbi3L",
        "z9KhglJ_eANT",
        "BqVLvcY9eEG5"
      ],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMf5PDBCyzNEY4ODARsQFdC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SonjaWangJQ/Keyboard-ML/blob/main/5_MFCC_data_amplifying.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load dataset"
      ],
      "metadata": {
        "id": "FKQzrqN7bmPb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97yR6vY716ke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3774da36-7c5c-40fe-8d21-b0add56366d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "58DoZIih9NwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import math, random\n",
        "import torch\n",
        "import torchaudio\n",
        "import librosa\n",
        "from torchaudio import transforms\n",
        "from IPython.display import Audio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import csv\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PrW8VowLfR4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class AudioUtil():\n",
        "  # ----------------------------\n",
        "  # Load an audio file. Return the signal as a tensor and the sample rate\n",
        "  # ----------------------------\n",
        "\n",
        "  @staticmethod\n",
        "  def open(audio_file):\n",
        "    sig, sr = torchaudio.load(audio_file)\n",
        "    return (sig, sr)\n",
        "\n",
        "\n",
        "\n",
        "    # ----------------------------\n",
        "  # 数据放大*1.1 and *0.9\n",
        "  # *1.1\n",
        "  #\n",
        "  @staticmethod\n",
        "  def time_Amp(aud, Amp_size):\n",
        "    sig,sr = aud\n",
        "    Amp_sig = sig * Amp_size\n",
        "    return (Amp_sig , sr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def compute_mfcc(aud, n_mfcc=32, window_size=0.01, step_size=0.0025, n_filters=32):\n",
        "\n",
        "            sig, sr = aud\n",
        "            n_fft = int(sr * window_size)\n",
        "            hop_length = int(sr * step_size)\n",
        "\n",
        "            mfccs = librosa.feature.mfcc(\n",
        "                y=sig.numpy(),\n",
        "                sr=sr,\n",
        "                n_mfcc=n_mfcc,\n",
        "                n_fft=n_fft,\n",
        "                hop_length=hop_length,\n",
        "                n_mels=n_filters\n",
        "            )\n",
        "            return mfccs.T\n",
        "  @staticmethod\n",
        "  def compute_stft(aud, n_fft=2048, hop_length=512, window='hann'):\n",
        "    sig, sr = aud\n",
        "    audio = sig.squeeze().numpy()\n",
        "\n",
        "    # Compute STFT\n",
        "    stft_result = librosa.core.stft(audio, n_fft=2048, hop_length=512, window='hann')\n",
        "\n",
        "    # Get magnitude spectrum\n",
        "    magnitude = np.abs(stft_result)\n",
        "\n",
        "    # Get frequency axis\n",
        "    freqs = librosa.core.fft_frequencies(sr=sr, n_fft=2048)\n",
        "\n",
        "    return freqs, magnitude @staticmethod\n",
        "  def compute_mfcc(aud,  window_size=0.01, step_size=0.0025, n_filters=32):\n",
        "\n",
        "            sig, sr = aud\n",
        "            n_fft = int(sr * window_size)\n",
        "            hop_length = int(sr * step_size)\n",
        "\n",
        "            mfccs = librosa.feature.mfcc(\n",
        "                y=sig.numpy(),\n",
        "                sr=sr,\n",
        "                n_mfcc=n_mfcc,\n",
        "                n_fft=n_fft,\n",
        "                hop_length=hop_length,\n",
        "                n_mels=n_filters\n",
        "            )\n",
        "            return mfccs.T\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def compute_fft(aud):\n",
        "\n",
        "            # 计算 FFT\n",
        "            sig, sr = aud\n",
        "            audio = sig.squeeze().numpy()\n",
        "            fft_result = np.fft.fft(audio)\n",
        "\n",
        "            # 获取频率轴\n",
        "            freqs = np.fft.fftfreq(len(audio), 1/sr)\n",
        "\n",
        "            # 获取频率强度谱\n",
        "            magnitude = np.abs(fft_result)\n",
        "\n",
        "            return freqs, magnitude\n"
      ],
      "metadata": {
        "id": "PiWvjS7hZm5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buLRPmQof9G5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# SoundDS1 no ampf\n",
        "# ----------------------------\n",
        "class SoundDS(Dataset):\n",
        "\n",
        "  def __init__(self, csv_filename):\n",
        "    self.csv_filename = csv_filename\n",
        "    self.sr = 44100\n",
        "    self.channel = 1\n",
        "    # self.shift_pct = -0.01   # +10ms\n",
        "    self.audio_file, self.class_id = self.load_datapath()\n",
        "\n",
        "\n",
        "  def load_datapath(self):\n",
        "        audio_file, class_id = [], []\n",
        "        with open(self.csv_filename) as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)  # Skip the header line\n",
        "            for row in reader:\n",
        "                i, l = row\n",
        "                audio_file.append(i)\n",
        "                class_id.append(int(l))  # Convert class ID to integer\n",
        "        return audio_file, class_id\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.audio_file)\n",
        "\n",
        "\n",
        "  def get_class_counts(self):\n",
        "        class_counts = {}\n",
        "        for cls_id in self.class_id:\n",
        "            if cls_id in class_counts:\n",
        "                class_counts[cls_id] += 1\n",
        "            else:\n",
        "                class_counts[cls_id] = 1\n",
        "        return class_counts\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    # Absolute file path of the audio file - concatenate the audio directory with\n",
        "    # the relative path，Get the Class ID\n",
        "\n",
        "    # Get the Class ID\n",
        "    audio_path = self.audio_file[idx]\n",
        "    class_id = self.class_id[idx]\n",
        "\n",
        "\n",
        "    aud = AudioUtil.open(audio_path)\n",
        "    Amp_aud = AudioUtil.time_Amp(aud,self.amp_size)\n",
        "    mfcc_aud = AudioUtil.compute_mfcc(Amp_aud)\n",
        "    mfcc_data = np.array(mfcc_aud)\n",
        "    # fft_audio = AudioUtil.compute_fft(shift_aud )\n",
        "    # fft_data = np.array(fft_audio)\n",
        "    # return mfcc_aud, class_id\n",
        "    return mfcc_aud, class_id, audio_path # for mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZJ5bBIVaSOY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# SoundDS1 1.1 ampf\n",
        "# ----------------------------\n",
        "class SoundDS1(Dataset):\n",
        "\n",
        "  def __init__(self, csv_filename):\n",
        "    self.csv_filename = csv_filename\n",
        "    self.sr = 44100\n",
        "    self.channel = 1\n",
        "    self.amp_size = 1.1  # 1.1\n",
        "    self.audio_file, self.class_id = self.load_datapath()\n",
        "\n",
        "\n",
        "  def load_datapath(self):\n",
        "        audio_file, class_id = [], []\n",
        "        with open(self.csv_filename) as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)  # Skip the header line\n",
        "            for row in reader:\n",
        "                i, l = row\n",
        "                audio_file.append(i)\n",
        "                class_id.append(int(l))  # Convert class ID to integer\n",
        "        return audio_file, class_id\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.audio_file)\n",
        "\n",
        "\n",
        "  def get_class_counts(self):\n",
        "        class_counts = {}\n",
        "        for cls_id in self.class_id:\n",
        "            if cls_id in class_counts:\n",
        "                class_counts[cls_id] += 1\n",
        "            else:\n",
        "                class_counts[cls_id] = 1\n",
        "        return class_counts\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    # Absolute file path of the audio file - concatenate the audio directory with\n",
        "    # the relative path，Get the Class ID\n",
        "\n",
        "    # Get the Class ID\n",
        "    audio_path = self.audio_file[idx]\n",
        "    class_id = self.class_id[idx]\n",
        "\n",
        "\n",
        "    aud = AudioUtil.open(audio_path)\n",
        "    Amp_aud = AudioUtil.time_Amp(aud, self.amp_size)\n",
        "    mfcc_aud = AudioUtil.compute_mfcc(Amp_aud)\n",
        "    mfcc_data = np.array(mfcc_aud)\n",
        "    # fft_audio = AudioUtil.compute_fft(shift_aud )\n",
        "    # fft_data = np.array(fft_audio)\n",
        "    # return mfcc_aud, class_id\n",
        "    return mfcc_aud, class_id, audio_path # for mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4KPJWYdagwO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# SoundDS1 0.9 ampf\n",
        "# ----------------------------\n",
        "class SoundDS2(Dataset):\n",
        "\n",
        "  def __init__(self, csv_filename):\n",
        "    self.csv_filename = csv_filename\n",
        "    self.sr = 44100\n",
        "    self.channel = 1\n",
        "    self.amp_size = 0.9 # 0.9\n",
        "    self.audio_file, self.class_id = self.load_datapath()\n",
        "\n",
        "\n",
        "  def load_datapath(self):\n",
        "        audio_file, class_id = [], []\n",
        "        with open(self.csv_filename) as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)  # Skip the header line\n",
        "            for row in reader:\n",
        "                i, l = row\n",
        "                audio_file.append(i)\n",
        "                class_id.append(int(l))  # Convert class ID to integer\n",
        "        return audio_file, class_id\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.audio_file)\n",
        "\n",
        "\n",
        "  def get_class_counts(self):\n",
        "        class_counts = {}\n",
        "        for cls_id in self.class_id:\n",
        "            if cls_id in class_counts:\n",
        "                class_counts[cls_id] += 1\n",
        "            else:\n",
        "                class_counts[cls_id] = 1\n",
        "        return class_counts\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    # Absolute file path of the audio file - concatenate the audio directory with\n",
        "    # the relative path，Get the Class ID\n",
        "\n",
        "    # Get the Class ID\n",
        "    audio_path = self.audio_file[idx]\n",
        "    class_id = self.class_id[idx]\n",
        "\n",
        "\n",
        "    aud = AudioUtil.open(audio_path)\n",
        "    Amp_aud = AudioUtil.time_Amp(aud, self.amp_size)\n",
        "    mfcc_aud = AudioUtil.compute_mfcc(Amp_aud)\n",
        "    mfcc_data = np.array(mfcc_aud)\n",
        "    # fft_audio = AudioUtil.compute_fft(shift_aud )\n",
        "    # fft_data = np.array(fft_audio)\n",
        "    # return mfcc_aud, class_id\n",
        "    return mfcc_aud, class_id, audio_path # for mapping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------\n",
        "# * 1\n",
        "# ----------------------------\n",
        "class SoundDS(Dataset):\n",
        "\n",
        "  def __init__(self, csv_filename):\n",
        "    self.csv_filename = csv_filename\n",
        "    self.sr = 44100\n",
        "    self.channel = 1\n",
        "    self.amp_size = 1\n",
        "    self.audio_file, self.class_id = self.load_datapath()\n",
        "\n",
        "\n",
        "  def load_datapath(self):\n",
        "        audio_file, class_id = [], []\n",
        "        with open(self.csv_filename) as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)  # Skip the header line\n",
        "            for row in reader:\n",
        "                i, l = row\n",
        "                audio_file.append(i)\n",
        "                class_id.append(int(l))  # Convert class ID to integer\n",
        "        return audio_file, class_id\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.audio_file)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    # Absolute file path of the audio file - concatenate the audio directory with\n",
        "    # the relative path，Get the Class ID\n",
        "\n",
        "    # Get the Class ID\n",
        "    audio_path = self.audio_file[idx]\n",
        "    class_id = self.class_id[idx]\n",
        "\n",
        "    aud = AudioUtil.open(audio_path)\n",
        "    # Amp_aud = AudioUtil.time_Amp(aud, self.amp_size)\n",
        "    mfcc_aud = AudioUtil.compute_mfcc(aud)\n",
        "    mfcc_data = np.array(mfcc_aud)\n",
        "    # fft_audio = AudioUtil.compute_fft(shift_aud )\n",
        "    # fft_data = np.array(fft_audio)\n",
        "\n",
        "    return mfcc_aud, class_id, audio_path\n"
      ],
      "metadata": {
        "id": "tuM2IQQNhU3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WiimhaWkQLt"
      },
      "outputs": [],
      "source": [
        "# shift  append into X,y\n",
        "csv_filename = \"/content/drive/MyDrive/collect_machinekeyboard/collect/piece2_441.csv\"\n",
        "sound_dataset_shift= SoundDS(csv_filename)\n",
        "X = []\n",
        "y = []\n",
        "path = []\n",
        "\n",
        "\n",
        "for idx in range(len(sound_dataset_shift)):\n",
        "    mfcc_data, class_id,audio_path = sound_dataset_shift[idx]\n",
        "    X.append(mfcc_data)\n",
        "    y.append(class_id)\n",
        "    path.append(audio_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zAAdGH65GwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "435859d6-3210-4335-9f55-33f6b3a15689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1467, 41, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "path = np.array(path)\n",
        "# check length\n",
        "assert X.shape[0] == len(y), \"Shape mismatch between X and y\"\n",
        "assert X.shape[0] == len(path), \"Shape mismatch between X and path\"\n",
        "print(X.shape)\n",
        "num_samples, num_frames, num_coefficients, num_channels = X.shape\n",
        "MFCC_data_2d = X.reshape(num_samples, num_frames * num_coefficients)\n",
        "\n",
        "\n",
        "X_shuffled, y_shuffled, path_shuffled  = shuffle(MFCC_data_2d, y, path, random_state=42)\n",
        "# X_shuffled, y_shuffled = shuffle(MFCC_data_2d, y, random_state=42)\n",
        "X_train, X_test, y_train, y_test, path_train, path_test = train_test_split(X_shuffled, y_shuffled, path_shuffled, train_size=0.8, random_state=42,stratify = y_shuffled)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape,y_test.shape,path_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLA7GNk2bClo",
        "outputId": "2e5ee337-4df3-4f0e-92d0-db3a82ad9953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1173,) (294,) (294,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train) # 标准化\n",
        "X_test_scaled = scaler.transform(X_test) # keep it\n",
        "print(X_train_scaled.shape, X_test_scaled.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXaKd-owfpYv",
        "outputId": "c7355ac6-a538-45c7-9865-261ea2ade0a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1173, 1312) (294, 1312)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### append new data"
      ],
      "metadata": {
        "id": "meYfx2fZbi3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_filename = \"/content/drive/MyDrive/collect_machinekeyboard/collect/piece2_441.csv\"\n",
        "sound_dataset_shift2 = SoundDS1(csv_filename)\n",
        "X2 = []\n",
        "y2 = []\n",
        "\n",
        "for idx in range(len(sound_dataset_shift2)):\n",
        "    mfcc_data2, class_id2, audio_path2 = sound_dataset_shift2[idx]  # 调用 __getitem__ 方法\n",
        "    if audio_path2 in path_train:\n",
        "        X2.append(mfcc_data2)\n",
        "        y2.append(class_id2)"
      ],
      "metadata": {
        "id": "O5WXqgPpdXfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# *0.9\n",
        "csv_filename = \"/content/drive/MyDrive/collect_machinekeyboard/collect/piece2_441.csv\"\n",
        "sound_dataset_shift3= SoundDS2(csv_filename)\n",
        "\n",
        "for idx in range(len(sound_dataset_shift3)):\n",
        "    mfcc_data3, class_id3, audio_path3 = sound_dataset_shift3[idx]  # 调用 __getitem__ 方法\n",
        "    if audio_path3 in path_train:\n",
        "        X2.append(mfcc_data3)\n",
        "        y2.append(class_id3)\n"
      ],
      "metadata": {
        "id": "j5NbZ92ehtph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X2 = np.array(X2)\n",
        "y2 = np.array(y2)\n",
        "# 检查 X 的行数与 y 的长度是否一致\n",
        "assert X2.shape[0] == len(y2), \"Shape mismatch between X and y\"\n",
        "print(X2.shape)\n",
        "num_samples, num_frames, num_coefficients, num_channels = X2.shape\n",
        "\n",
        "new_X2train = X2.reshape(num_samples, num_frames * num_coefficients)\n",
        "print(new_X2train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj5kMTA9fugE",
        "outputId": "e2d27e18-7b9e-4b6a-d236-97a09a2a1ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2346, 41, 32, 1)\n",
            "(2346, 1312)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X2_shuffled, y2_shuffled = shuffle( new_X2train , y2, random_state=42)\n",
        "new_X2_train_scaled = scaler.fit_transform(X2_shuffled)\n",
        "print(new_X2_train_scaled.shape, y2_shuffled)\n"
      ],
      "metadata": {
        "id": "DZUr4RbfdnAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf75c11-0066-4d13-f015-703cd2ada99e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2346, 1312) [11  5 15 ... 34  6 17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# append X_train, y_train\n",
        "X_train_extended = np.vstack([X_train_scaled, new_X2_train_scaled])\n",
        "y_train_extended = np.concatenate([y_train, y2_shuffled])"
      ],
      "metadata": {
        "id": "yGLG7Qkzdsj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(np.unique(y_train_extended)) # 或者使用 len(np.unique(y_test))\n",
        "print(y_train_extended)\n",
        "print(\"Number of classes:\", num_classes)"
      ],
      "metadata": {
        "id": "WQV3lOBNduL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b92a3eb-243b-444f-808c-917482cc68c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20 12 32 ... 34  6 17]\n",
            "Number of classes: 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_extended.shape,y_train_extended.shape)\n",
        "print(X_test_scaled.shape, y_test.shape)\n",
        "# print(X_val_scaled.shape,X_test_scaled.shape, y_test.shape,y_valid.shape,)"
      ],
      "metadata": {
        "id": "VV-mntxPdvws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc52c87e-3422-4370-d57a-22212a9ba353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3519, 1312) (3519,)\n",
            "(294, 1312) (294,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## amf train"
      ],
      "metadata": {
        "id": "z9KhglJ_eANT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### svm"
      ],
      "metadata": {
        "id": "BqVLvcY9eEG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "SxJbX3g_eHFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vcme4kBSImJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbf8bd97-e4ed-4c32-d472-462567970854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.75      0.75      0.75         8\n",
            "     Class 1       0.82      1.00      0.90         9\n",
            "     Class 2       1.00      1.00      1.00         9\n",
            "     Class 3       0.73      0.80      0.76        10\n",
            "     Class 4       0.90      1.00      0.95         9\n",
            "     Class 5       0.89      1.00      0.94         8\n",
            "     Class 6       1.00      0.78      0.88         9\n",
            "     Class 7       0.90      0.90      0.90        10\n",
            "     Class 8       0.82      0.90      0.86        10\n",
            "     Class 9       0.77      1.00      0.87        10\n",
            "    Class 10       1.00      0.86      0.92         7\n",
            "    Class 11       1.00      0.89      0.94         9\n",
            "    Class 12       1.00      0.75      0.86         8\n",
            "    Class 13       0.83      0.71      0.77         7\n",
            "    Class 14       0.70      0.78      0.74         9\n",
            "    Class 15       0.90      1.00      0.95         9\n",
            "    Class 16       0.86      0.75      0.80         8\n",
            "    Class 17       0.89      0.73      0.80        11\n",
            "    Class 18       1.00      0.57      0.73         7\n",
            "    Class 19       0.62      0.83      0.71         6\n",
            "    Class 20       1.00      0.90      0.95        10\n",
            "    Class 21       0.90      1.00      0.95         9\n",
            "    Class 22       0.89      0.89      0.89         9\n",
            "    Class 23       1.00      1.00      1.00        10\n",
            "    Class 24       1.00      0.89      0.94         9\n",
            "    Class 25       0.88      0.78      0.82         9\n",
            "    Class 26       1.00      1.00      1.00         5\n",
            "    Class 27       1.00      0.83      0.91         6\n",
            "    Class 28       0.70      0.88      0.78         8\n",
            "    Class 29       0.67      0.50      0.57         4\n",
            "    Class 30       1.00      1.00      1.00         6\n",
            "    Class 31       0.78      0.78      0.78         9\n",
            "    Class 32       0.88      0.88      0.88         8\n",
            "    Class 33       0.83      1.00      0.91         5\n",
            "    Class 34       0.75      0.86      0.80         7\n",
            "    Class 35       0.57      0.57      0.57         7\n",
            "\n",
            "    accuracy                           0.86       294\n",
            "   macro avg       0.87      0.85      0.85       294\n",
            "weighted avg       0.87      0.86      0.86       294\n",
            "\n",
            "Top-1 Accuracy Score: 0.8571\n",
            "Top-2 Accuracy Score: 0.9354\n",
            "Top-3 Accuracy Score: 0.9490\n",
            "Top-4 Accuracy Score: 0.9660\n",
            "Top-5 Accuracy Score: 0.9660\n"
          ]
        }
      ],
      "source": [
        "#SVM model\n",
        "# data shift\n",
        "# X_train_extended.shape,y_train_extended.shape\n",
        "# Best parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "\n",
        "param_grid = {\n",
        "    'C': [1],\n",
        "    'kernel': ['linear'],\n",
        "    # 'gamma': ['scale', 'auto', 0.1, 0.01, 0.001]\n",
        "    'gamma':[\"scale\"]\n",
        "    }\n",
        "\n",
        "#  SVM model\n",
        "svm = SVC()\n",
        "\n",
        "#  grid search object with 10-fold cross-validation\n",
        "# grid_search = GridSearchCV(svm, param_grid, cv=10, n_jobs=-1)\n",
        "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=10, n_jobs=-1) # 新修改\n",
        "grid_search.fit(X_train_extended, y_train_extended)\n",
        "# grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "#  best model from grid search\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict using the best model\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "target_names = [f'Class {i}' for i in range(36)]\n",
        "#   classification report\n",
        "cr = classification_report(y_test, y_pred, target_names=target_names)\n",
        "# TOP 5 ACCURACY\n",
        "N_values = [1, 2, 3, 4, 5]\n",
        "top_n_accuracies = [top_k_accuracy_score(y_test, best_model.decision_function(X_test_scaled), k=N) for N in N_values]\n",
        "\n",
        "# Print results\n",
        "print(\"parameters:\", grid_search.best_params_)\n",
        "print(\"Classification Report:\")\n",
        "print(cr)\n",
        "for N, accuracy in zip(N_values, top_n_accuracies):\n",
        "    print(f\"Top-{N} Accuracy Score: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLR"
      ],
      "metadata": {
        "id": "rqZxOaTXeKyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "multi_logreg = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\",max_iter=1000)\n",
        "\n",
        "# parameters: {'C': 1, 'penalty': 'l2'}\n",
        "param_grid = {\n",
        "    'C': [ 1 ],\n",
        "    'penalty': ['l2']\n",
        "}\n",
        "\n",
        "# 10 fold across\n",
        "grid_search = GridSearchCV(multi_logreg, param_grid, cv=10, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train_extended, y_train_extended) # *3\n",
        "print(\"parameters:\", grid_search.best_params_)\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "\n",
        "target_names = [f'Class {i}' for i in range(36)]\n",
        "\n",
        "# report\n",
        "cr = classification_report(y_test, y_pred, target_names=target_names)\n",
        "\n",
        "# Top-N accuracy score\n",
        "N_values = [1, 2, 3, 4, 5]\n",
        "top_n_accuracies = [top_k_accuracy_score(y_test, best_model.predict_proba(X_test_scaled), k=N) for N in N_values]\n",
        "\n",
        "# Print top-N accuracy scores\n",
        "for N, accuracy in zip(N_values, top_n_accuracies):\n",
        "    print(f\"Top-{N} Accuracy Score: {accuracy:.4f}\")\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "mHds0cmDHE9U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27fcf544-95c3-4b79-8d22-6f50a2faf461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "parameters: {'C': 1, 'penalty': 'l2'}\n",
            "Top-1 Accuracy Score: 0.8673\n",
            "Top-2 Accuracy Score: 0.9252\n",
            "Top-3 Accuracy Score: 0.9626\n",
            "Top-4 Accuracy Score: 0.9728\n",
            "Top-5 Accuracy Score: 0.9728\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.71      0.62      0.67         8\n",
            "     Class 1       0.80      0.89      0.84         9\n",
            "     Class 2       1.00      0.89      0.94         9\n",
            "     Class 3       0.77      1.00      0.87        10\n",
            "     Class 4       0.89      0.89      0.89         9\n",
            "     Class 5       1.00      1.00      1.00         8\n",
            "     Class 6       0.88      0.78      0.82         9\n",
            "     Class 7       0.91      1.00      0.95        10\n",
            "     Class 8       0.82      0.90      0.86        10\n",
            "     Class 9       0.91      1.00      0.95        10\n",
            "    Class 10       1.00      0.71      0.83         7\n",
            "    Class 11       0.80      0.89      0.84         9\n",
            "    Class 12       0.88      0.88      0.88         8\n",
            "    Class 13       1.00      0.86      0.92         7\n",
            "    Class 14       0.88      0.78      0.82         9\n",
            "    Class 15       1.00      1.00      1.00         9\n",
            "    Class 16       0.75      0.75      0.75         8\n",
            "    Class 17       0.71      0.91      0.80        11\n",
            "    Class 18       0.75      0.86      0.80         7\n",
            "    Class 19       0.67      1.00      0.80         6\n",
            "    Class 20       1.00      0.90      0.95        10\n",
            "    Class 21       1.00      1.00      1.00         9\n",
            "    Class 22       0.89      0.89      0.89         9\n",
            "    Class 23       1.00      1.00      1.00        10\n",
            "    Class 24       1.00      0.89      0.94         9\n",
            "    Class 25       0.89      0.89      0.89         9\n",
            "    Class 26       1.00      0.60      0.75         5\n",
            "    Class 27       1.00      0.67      0.80         6\n",
            "    Class 28       1.00      0.75      0.86         8\n",
            "    Class 29       1.00      0.50      0.67         4\n",
            "    Class 30       1.00      1.00      1.00         6\n",
            "    Class 31       0.70      0.78      0.74         9\n",
            "    Class 32       0.86      0.75      0.80         8\n",
            "    Class 33       0.83      1.00      0.91         5\n",
            "    Class 34       0.67      0.86      0.75         7\n",
            "    Class 35       0.83      0.71      0.77         7\n",
            "\n",
            "    accuracy                           0.87       294\n",
            "   macro avg       0.88      0.86      0.86       294\n",
            "weighted avg       0.88      0.87      0.87       294\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RF"
      ],
      "metadata": {
        "id": "awAbPx1deZs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pydot\n",
        "import scipy.stats as stats\n",
        "from pprint import pprint\n",
        "from sklearn import metrics\n",
        "from openpyxl import load_workbook\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import KFold, cross_val_predict\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming you have loaded X_train_scaled, y_train, X_test_scaled, and y_test\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {\n",
        "    'n_estimators': [100],\n",
        "    'max_depth': [None],\n",
        "    'min_samples_split': [10],\n",
        "    'min_samples_leaf': [4],\n",
        "    'bootstrap': [False]\n",
        "}\n",
        "# {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
        "# Create and fit the Random Forest model using GridSearchCV\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(random_forest, param_grid, cv=10, n_jobs=-1)\n",
        "grid_search.fit(X_train_extended, y_train_extended)\n",
        "\n",
        "best_random_forest = grid_search.best_estimator_\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "y_test_pred_probs = cross_val_predict(best_random_forest, X_test_scaled, y_test, cv=kf, method='predict_proba')\n",
        "\n",
        "# ... (Rest of your code for calculating top-N accuracy scores and generating the classification report)\n",
        "N_values = [1, 2, 3, 4, 5]\n",
        "top_n_accuracies = []\n",
        "for N in N_values:\n",
        "    top_n_correct = 0\n",
        "    for true_label, pred_probs in zip(y_test, y_test_pred_probs):\n",
        "        top_n_indices = np.argsort(pred_probs)[::-1][:N]  # Indices of top-N classes\n",
        "        if true_label in top_n_indices:\n",
        "            top_n_correct += 1\n",
        "    top_n_accuracy = top_n_correct / len(y_test)\n",
        "    top_n_accuracies.append(top_n_accuracy)\n",
        "\n",
        "# Print the best hyperparameters found by GridSearchCV\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Print top-N accuracy scores\n",
        "for N, accuracy in zip(N_values, top_n_accuracies):\n",
        "    print(f\"Top-{N} Accuracy Score: {accuracy:.4f}\")\n",
        "\n",
        "# Generate classification report\n",
        "target_names = [f'Class {i}' for i in range(36)]\n",
        "y_test_pred = np.argmax(y_test_pred_probs, axis=1)\n",
        "cr = classification_report(y_test, y_test_pred, target_names=target_names)\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(cr)\n",
        "\n"
      ],
      "metadata": {
        "id": "zsYo132uXgTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffdca924-65cf-4546-dee1-865f27414f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters:\n",
            "{'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
            "Top-1 Accuracy Score: 0.2789\n",
            "Top-2 Accuracy Score: 0.3946\n",
            "Top-3 Accuracy Score: 0.4558\n",
            "Top-4 Accuracy Score: 0.5000\n",
            "Top-5 Accuracy Score: 0.5544\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.50      0.12      0.20         8\n",
            "     Class 1       0.31      0.44      0.36         9\n",
            "     Class 2       0.31      0.44      0.36         9\n",
            "     Class 3       0.09      0.10      0.10        10\n",
            "     Class 4       0.22      0.22      0.22         9\n",
            "     Class 5       0.75      0.38      0.50         8\n",
            "     Class 6       0.33      0.33      0.33         9\n",
            "     Class 7       0.33      0.50      0.40        10\n",
            "     Class 8       0.60      0.30      0.40        10\n",
            "     Class 9       0.33      0.60      0.43        10\n",
            "    Class 10       0.00      0.00      0.00         7\n",
            "    Class 11       0.46      0.67      0.55         9\n",
            "    Class 12       0.00      0.00      0.00         8\n",
            "    Class 13       0.00      0.00      0.00         7\n",
            "    Class 14       0.14      0.11      0.12         9\n",
            "    Class 15       0.10      0.11      0.11         9\n",
            "    Class 16       0.00      0.00      0.00         8\n",
            "    Class 17       0.09      0.09      0.09        11\n",
            "    Class 18       0.67      0.29      0.40         7\n",
            "    Class 19       0.00      0.00      0.00         6\n",
            "    Class 20       0.26      0.60      0.36        10\n",
            "    Class 21       0.41      0.78      0.54         9\n",
            "    Class 22       0.29      0.56      0.38         9\n",
            "    Class 23       0.31      0.50      0.38        10\n",
            "    Class 24       0.17      0.22      0.19         9\n",
            "    Class 25       0.50      0.22      0.31         9\n",
            "    Class 26       0.00      0.00      0.00         5\n",
            "    Class 27       0.67      0.33      0.44         6\n",
            "    Class 28       0.25      0.25      0.25         8\n",
            "    Class 29       0.00      0.00      0.00         4\n",
            "    Class 30       0.50      0.33      0.40         6\n",
            "    Class 31       0.13      0.22      0.17         9\n",
            "    Class 32       0.29      0.25      0.27         8\n",
            "    Class 33       0.00      0.00      0.00         5\n",
            "    Class 34       0.20      0.29      0.24         7\n",
            "    Class 35       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.28       294\n",
            "   macro avg       0.26      0.26      0.24       294\n",
            "weighted avg       0.27      0.28      0.25       294\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}