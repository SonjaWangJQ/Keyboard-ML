{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SonjaWangJQ/Keyboard-ML/blob/main/3_FFT_on_claasifer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LOAD DATA"
      ],
      "metadata": {
        "id": "Diy3CsNpevhy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97yR6vY716ke",
        "outputId": "9fdab37c-b0a5-4fb0-d7dd-413496dab630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58DoZIih9NwA"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFEiegTHkRjQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import math, random\n",
        "import torch\n",
        "import torchaudio\n",
        "import librosa\n",
        "from torchaudio import transforms\n",
        "from IPython.display import Audio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import csv\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiWvjS7hZm5q"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class AudioUtil():\n",
        "  # ----------------------------\n",
        "  # Load an audio file. Return the signal as a tensor and the sample rate\n",
        "  # ----------------------------\n",
        "\n",
        "  @staticmethod\n",
        "  def open(audio_file):\n",
        "    sig, sr = torchaudio.load(audio_file)\n",
        "    return (sig, sr)\n",
        "\n",
        "\n",
        "\n",
        "    # ----------------------------\n",
        "  # 数据扩充--时间移动（1）\n",
        "  #7\n",
        "  @staticmethod\n",
        "  def time_shift(aud, shift_limit):\n",
        "    sig,sr = aud\n",
        "    _, sig_len = sig.shape\n",
        "    shift_amt = int(random.random() * shift_limit * sig_len)\n",
        "    return (sig.roll(shift_amt), sr)\n",
        "\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def compute_mfcc(aud, n_mfcc=32, window_size=0.01, step_size=0.0025, n_filters=32):\n",
        "\n",
        "            sig, sr = aud\n",
        "            n_fft = int(sr * window_size)\n",
        "            hop_length = int(sr * step_size)\n",
        "\n",
        "            mfccs = librosa.feature.mfcc(\n",
        "                y=sig.numpy(),\n",
        "                sr=sr,\n",
        "                n_mfcc=n_mfcc,\n",
        "                n_fft=n_fft,\n",
        "                hop_length=hop_length,\n",
        "                n_mels=n_filters\n",
        "            )\n",
        "            return mfccs.T\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def compute_stft(aud, n_fft=2048, hop_length=512, window='hann'):\n",
        "    sig, sr = aud\n",
        "    audio = sig.squeeze().numpy()\n",
        "\n",
        "    # Compute STFT\n",
        "    stft_result = librosa.core.stft(audio, n_fft=2048, hop_length=512, window='hann')\n",
        "\n",
        "    # Get magnitude spectrum\n",
        "    magnitude = np.abs(stft_result)\n",
        "\n",
        "    # Get frequency axis\n",
        "    freqs = librosa.core.fft_frequencies(sr=sr, n_fft=2048)\n",
        "\n",
        "    return magnitude\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXD124mde-tc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# SoundDS +10ms\n",
        "# ----------------------------\n",
        "class SoundDS1(Dataset):\n",
        "\n",
        "  def __init__(self, csv_filename):\n",
        "    self.csv_filename = csv_filename\n",
        "    # self.train_indices = train_indices  # 训练集的索引列表\n",
        "    self.sr = 44100\n",
        "    self.channel = 1\n",
        "    self.shift_pct = 0.01   # +10ms\n",
        "    self.audio_file, self.class_id = self.load_datapath()\n",
        "\n",
        "\n",
        "  def load_datapath(self):\n",
        "        audio_file, class_id = [], []\n",
        "        with open(self.csv_filename) as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)  # Skip the header line\n",
        "            for row in reader:\n",
        "                i, l = row\n",
        "                audio_file.append(i)\n",
        "                class_id.append(int(l))  # Convert class ID to integer\n",
        "        return audio_file, class_id\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.audio_file)\n",
        "\n",
        "\n",
        "  def get_class_counts(self):\n",
        "        class_counts = {}\n",
        "        for cls_id in self.class_id:\n",
        "            if cls_id in class_counts:\n",
        "                class_counts[cls_id] += 1\n",
        "            else:\n",
        "                class_counts[cls_id] = 1\n",
        "        return class_counts\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    # Absolute file path of the audio file - concatenate the audio directory with\n",
        "    # the relative path，Get the Class ID\n",
        "\n",
        "    # Get the Class ID\n",
        "    audio_path = self.audio_file[idx]\n",
        "    class_id = self.class_id[idx]\n",
        "\n",
        "\n",
        "    aud = AudioUtil.open(audio_path)\n",
        "    shift_aud = AudioUtil.time_shift(aud, self.shift_pct)\n",
        "    # mfcc_aud = AudioUtil.compute_mfcc(shift_aud)\n",
        "    # mfcc_data = np.array(mfcc_aud)\n",
        "    fft_audio = AudioUtil.compute_stft(shift_aud )\n",
        "    fft_data = np.array(fft_audio)\n",
        "\n",
        "    return fft_audio, class_id, audio_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd-Ao1uXfezu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# SoundDS2 -10ms\n",
        "# ----------------------------\n",
        "class SoundDS2(Dataset):\n",
        "\n",
        "  def __init__(self, csv_filename):\n",
        "    self.csv_filename = csv_filename\n",
        "    # self.train_indices = train_indices # 训练集的索引列表\n",
        "    self.sr = 44100\n",
        "    self.channel = 1\n",
        "    self.shift_pct = -0.01   # +10ms\n",
        "    self.audio_file, self.class_id = self.load_datapath()\n",
        "\n",
        "\n",
        "  def load_datapath(self):\n",
        "        audio_file, class_id = [], []\n",
        "        with open(self.csv_filename) as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)  # Skip the header line\n",
        "            for row in reader:\n",
        "                i, l = row\n",
        "                audio_file.append(i)\n",
        "                class_id.append(int(l))  # Convert class ID to integer\n",
        "        return audio_file, class_id\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.audio_file)\n",
        "\n",
        "  def get_class_counts(self):\n",
        "        class_counts = {}\n",
        "        for cls_id in self.class_id:\n",
        "            if cls_id in class_counts:\n",
        "                class_counts[cls_id] += 1\n",
        "            else:\n",
        "                class_counts[cls_id] = 1\n",
        "        return class_counts\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    # Absolute file path of the audio file - concatenate the audio directory with\n",
        "    # the relative path，Get the Class ID\n",
        "\n",
        "    # Get the Class ID\n",
        "    audio_path = self.audio_file[idx]\n",
        "    class_id = self.class_id[idx]\n",
        "\n",
        "    aud = AudioUtil.open(audio_path)\n",
        "    shift_aud = AudioUtil.time_shift(aud, self.shift_pct)\n",
        "    # mfcc_aud = AudioUtil.compute_mfcc(shift_aud)\n",
        "    # mfcc_data = np.array(mfcc_aud)\n",
        "    fft_audio = AudioUtil.compute_stft(shift_aud )\n",
        "    fft_data = np.array(fft_audio)\n",
        "\n",
        "    return fft_data, class_id, audio_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buLRPmQof9G5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# SoundDS1 no shift\n",
        "# ----------------------------\n",
        "class SoundDS(Dataset):\n",
        "\n",
        "  def __init__(self, csv_filename):\n",
        "    self.csv_filename = csv_filename\n",
        "    self.sr = 44100\n",
        "    self.channel = 1\n",
        "    # self.shift_pct = -0.01   # +10ms\n",
        "    self.audio_file, self.class_id = self.load_datapath()\n",
        "\n",
        "\n",
        "  def load_datapath(self):\n",
        "        audio_file, class_id = [], []\n",
        "        with open(self.csv_filename) as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)  # Skip the header line\n",
        "            for row in reader:\n",
        "                i, l = row\n",
        "                audio_file.append(i)\n",
        "                class_id.append(int(l))  # Convert class ID to integer\n",
        "        return audio_file, class_id\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.audio_file)\n",
        "\n",
        "\n",
        "  def get_class_counts(self):\n",
        "        class_counts = {}\n",
        "        for cls_id in self.class_id:\n",
        "            if cls_id in class_counts:\n",
        "                class_counts[cls_id] += 1\n",
        "            else:\n",
        "                class_counts[cls_id] = 1\n",
        "        return class_counts\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    # Absolute file path of the audio file - concatenate the audio directory with\n",
        "    # the relative path，Get the Class ID\n",
        "\n",
        "    # Get the Class ID\n",
        "    audio_path = self.audio_file[idx]\n",
        "    class_id = self.class_id[idx]\n",
        "\n",
        "    aud = AudioUtil.open(audio_path)\n",
        "    # shift_aud = AudioUtil.time_shift(aud, self.shift_pct)\n",
        "    # mfcc_aud = AudioUtil.compute_mfcc(aud)\n",
        "    # mfcc_data = np.array(mfcc_aud)\n",
        "    fft_audio = AudioUtil.compute_stft(aud)\n",
        "    fft_data = np.array(fft_audio)\n",
        "\n",
        "    return fft_data, class_id, audio_path # 为了创建映射\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOzq-fqn19XX"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_filename = \"/content/drive/MyDrive/collect_machinekeyboard/collect/piece2_441.csv\"\n",
        "sound_dataset= SoundDS(csv_filename)\n",
        "# dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
        "X = []\n",
        "y = []\n",
        "path = []\n",
        "for idx in range(len(sound_dataset)):\n",
        "    fft_data, class_id, audio_path = sound_dataset[idx]  # 调用 __getitem__ 方法\n",
        "    X.append(fft_data)\n",
        "    y.append(class_id)\n",
        "    path.append(audio_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "oQpAW9PznEOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "path = np.array(path)\n",
        "print(X.shape,y.shape)\n",
        "# 检查 X 的行数与 y 的长度是否一致\n",
        "assert X.shape[0] == len(y), \"Shape mismatch between X and y\"\n",
        "assert X.shape[0] == len(path), \"Shape mismatch between X and path\"\n",
        "# X_train,y 0.2\n",
        "X_input = X.reshape(X.shape[0], -1)  # Reshape to (1173, 1025*9)\n",
        "\n",
        "X_train, X_test, y_train, y_test,path_train, path_test = train_test_split(X_input, y,path, test_size=0.2, random_state=42, stratify=y)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngLWjBTmnfrb",
        "outputId": "626d733b-6e95-450c-c4ac-8c6a6e5f1d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1467, 1025, 9) (1467,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_test.shape, y_test.shape,path_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQEXuhYLn7O4",
        "outputId": "262c12ea-0cd3-48bd-efee-1dfd92dfab7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1173, 9225) (294, 9225) (294,) (1173,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(X_train_scaled.shape, X_test_scaled.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkfYTCd4zksz",
        "outputId": "fe158a0a-81c5-47eb-eed4-3a240a6b39f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1173, 9225) (294, 9225)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlo9jXb86Qb7"
      },
      "source": [
        "这时我们得到了train data路径, path-train(0.2*1407,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNyGD_WY5tLG"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### APPEND NEW"
      ],
      "metadata": {
        "id": "kDnuDzkRn-9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shift -10 append into X,y\n",
        "csv_filename = \"/content/drive/MyDrive/collect_machinekeyboard/collect/piece2_441.csv\"\n",
        "sound_dataset_shift2= SoundDS1(csv_filename)\n",
        "X2 = []\n",
        "y2 = []\n",
        "\n",
        "for idx in range(len(sound_dataset_shift2)):\n",
        "    fft_data2, class_id2, audio_path2 = sound_dataset_shift2[idx]  # 调用 __getitem__ 方法\n",
        "    if audio_path2 in path_train:\n",
        "        X2.append(fft_data2)\n",
        "        y2.append(class_id2)\n"
      ],
      "metadata": {
        "id": "pqzUoeyNn-PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "csv_filename = \"/content/drive/MyDrive/collect_machinekeyboard/collect/piece2_441.csv\"\n",
        "sound_dataset_shift3= SoundDS2(csv_filename)\n",
        "\n",
        "for idx in range(len(sound_dataset_shift3)):\n",
        "    fft_data3, class_id3, audio_path3 = sound_dataset_shift3[idx]  # 调用 __getitem__ 方法\n",
        "    if audio_path3 in path_train:\n",
        "        X2.append(fft_data3)\n",
        "        y2.append(class_id3)"
      ],
      "metadata": {
        "id": "cqUFfJgmoW8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJzFut5eipDb",
        "outputId": "192c14c2-da83-4e56-fe69-d29ff8606953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2346, 1312)\n"
          ]
        }
      ],
      "source": [
        "X2 = np.array(X2)\n",
        "y2 = np.array(y2)\n",
        "# 检查 X 的行数与 y 的长度是否一致\n",
        "assert X2.shape[0] == len(y2), \"Shape mismatch between X and y\"\n",
        "num_samples, num_frames, num_coefficients, num_channels = X2.shape\n",
        "\n",
        "new_X2train = X2.reshape(num_samples, num_frames * num_coefficients)\n",
        "print(new_X2train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il_vrf2a1-ro"
      },
      "source": [
        "# new append sample number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf4801zaM-WR",
        "outputId": "5c543c19-3ca1-43d9-afc2-b630c430a674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2346, 1312) [11  5 15 ... 34  6 17]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X2_shuffled, y2_shuffled = shuffle( new_X2train , y2, random_state=42)\n",
        "new_X2_train_scaled = scaler.fit_transform(X2_shuffled)\n",
        "print(new_X2_train_scaled.shape, y2_shuffled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUFEBGyMPRyS"
      },
      "outputs": [],
      "source": [
        "# append X_train, y_train\n",
        "X_train_extended = np.vstack([X_train_scaled, new_X2_train_scaled])\n",
        "y_train_extended = np.concatenate([y_train, y2_shuffled])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Wqw3FUiwaRW",
        "outputId": "8439bdb6-f89e-48a1-82e5-c80230e11426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20 12 32 ... 34  6 17]\n",
            "Number of classes: 36\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(np.unique(y_train_extended)) # 或者使用 len(np.unique(y_test))\n",
        "print(y_train_extended)\n",
        "print(\"Number of classes:\", num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvunGZzfQ9A2",
        "outputId": "ddb03058-1139-4b21-a134-b8c43554635b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3519, 1312) (3519,)\n",
            "(294, 1312) (294,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train_extended.shape,y_train_extended.shape)\n",
        "print(X_test_scaled.shape, y_test.shape)\n",
        "# print(X_val_scaled.shape,X_test_scaled.shape, y_test.shape,y_valid.shape,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNigst-37J_q"
      },
      "source": [
        "**start training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yC_0oQyo7QR"
      },
      "source": [
        "# SVM model 使用原数据训练结果 fft_SVM数据shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Tree3y_oSvl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56199e4e-df7c-4adb-bdc3-b56f976cd299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.62      0.62      0.62         8\n",
            "     Class 1       1.00      0.67      0.80         9\n",
            "     Class 2       0.60      0.33      0.43         9\n",
            "     Class 3       0.50      0.60      0.55        10\n",
            "     Class 4       0.31      0.89      0.46         9\n",
            "     Class 5       0.67      0.25      0.36         8\n",
            "     Class 6       0.58      0.78      0.67         9\n",
            "     Class 7       0.73      0.80      0.76        10\n",
            "     Class 8       0.50      0.80      0.62        10\n",
            "     Class 9       0.50      0.60      0.55        10\n",
            "    Class 10       0.83      0.71      0.77         7\n",
            "    Class 11       0.38      0.33      0.35         9\n",
            "    Class 12       1.00      0.50      0.67         8\n",
            "    Class 13       0.67      0.29      0.40         7\n",
            "    Class 14       0.75      0.33      0.46         9\n",
            "    Class 15       1.00      0.56      0.71         9\n",
            "    Class 16       0.33      0.12      0.18         8\n",
            "    Class 17       0.23      0.64      0.34        11\n",
            "    Class 18       0.20      0.14      0.17         7\n",
            "    Class 19       0.67      0.33      0.44         6\n",
            "    Class 20       0.54      0.70      0.61        10\n",
            "    Class 21       0.80      0.44      0.57         9\n",
            "    Class 22       0.55      0.67      0.60         9\n",
            "    Class 23       0.67      0.40      0.50        10\n",
            "    Class 24       1.00      0.67      0.80         9\n",
            "    Class 25       0.75      0.67      0.71         9\n",
            "    Class 26       1.00      0.60      0.75         5\n",
            "    Class 27       1.00      0.50      0.67         6\n",
            "    Class 28       0.75      0.75      0.75         8\n",
            "    Class 29       1.00      0.75      0.86         4\n",
            "    Class 30       0.00      0.00      0.00         6\n",
            "    Class 31       0.16      0.44      0.24         9\n",
            "    Class 32       0.50      0.38      0.43         8\n",
            "    Class 33       0.50      0.40      0.44         5\n",
            "    Class 34       0.67      0.57      0.62         7\n",
            "    Class 35       0.80      0.57      0.67         7\n",
            "\n",
            "    accuracy                           0.53       294\n",
            "   macro avg       0.63      0.52      0.54       294\n",
            "weighted avg       0.62      0.53      0.54       294\n",
            "\n",
            "Top-1 Accuracy Score: 0.5170\n",
            "Top-2 Accuracy Score: 0.6156\n",
            "Top-3 Accuracy Score: 0.6599\n",
            "Top-4 Accuracy Score: 0.7279\n",
            "Top-5 Accuracy Score: 0.7517\n"
          ]
        }
      ],
      "source": [
        "#SVM model 使用原数据训练结果\n",
        "#MFCC_SVM数据shift\n",
        "# Best parameters: {'C': 10, 'kernel': 'rbf'} 0.84\n",
        "#Mfcc: aud, n_mfcc=26, window_size=0.01, step_size=0.0025, n_filters=64\n",
        "#  parameter grid for grid search\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'C': [1, 5, 10, 100],\n",
        "    # 'C': [10],\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto', 0.1, 0.01, 0.001]\n",
        "    # 'gamma':[0.001]\n",
        "    }\n",
        "\n",
        "#  SVM model\n",
        "svm = SVC()\n",
        "\n",
        "#  grid search object with 10-fold cross-validation\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=10, n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "#  best model from grid search\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict using the best model\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "target_names = [f'Class {i}' for i in range(36)]\n",
        "#   classification report\n",
        "cr = classification_report(y_test, y_pred, target_names=target_names)\n",
        "# N = 5  # Change this to the desired value\n",
        "# top_n_accuracy = top_k_accuracy_score(y_test, best_model.decision_function(X_test_scaled), k=N)\n",
        "\n",
        "\n",
        "\n",
        "N_values = [1, 2, 3, 4, 5]\n",
        "top_n_accuracies = [top_k_accuracy_score(y_test, best_model.decision_function(X_test_scaled), k=N) for N in N_values]\n",
        "\n",
        "# Print results\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Classification Report:\")\n",
        "print(cr)\n",
        "for N, accuracy in zip(N_values, top_n_accuracies):\n",
        "    print(f\"Top-{N} Accuracy Score: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.ticker import PercentFormatter\n",
        "# Plotting the top-N accuracy scores\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(N_values, top_n_accuracies, marker='o')\n",
        "plt.ylim(0, 1)  # Set y-axis limits between 0 and 1\n",
        "plt.xticks(N_values)\n",
        "plt.xlabel(\"Number of guesses\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "# plt.title(\"\")\n",
        "plt.gca().yaxis.set_major_formatter(PercentFormatter(xmax=1)) # %\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D91xgMse5UqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTyev0xCIhWp"
      },
      "source": [
        "### data shift +- 10ms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vcme4kBSImJJ"
      },
      "outputs": [],
      "source": [
        "#SVM model\n",
        "# data shift\n",
        "# X_train_extended.shape,y_train_extended.shape\n",
        "# Best parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'C': [1],\n",
        "    'kernel': ['linear'],\n",
        "    # 'gamma': ['scale', 'auto', 0.1, 0.01, 0.001]\n",
        "    'gamma':[\"scale\"]\n",
        "    }\n",
        "\n",
        "#  SVM model\n",
        "svm = SVC()\n",
        "\n",
        "#  grid search object with 10-fold cross-validation\n",
        "# grid_search = GridSearchCV(svm, param_grid, cv=10, n_jobs=-1)\n",
        "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=10, n_jobs=-1) # 新修改\n",
        "grid_search.fit(X_train_extended, y_train_extended)\n",
        "# grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "#  best model from grid search\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict using the best model\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "target_names = [f'Class {i}' for i in range(36)]\n",
        "#   classification report\n",
        "cr = classification_report(y_test, y_pred, target_names=target_names)\n",
        "# TOP 5 ACCURACY\n",
        "N_values = [1, 2, 3, 4, 5]\n",
        "top_n_accuracies = [top_k_accuracy_score(y_test, best_model.decision_function(X_test_scaled), k=N) for N in N_values]\n",
        "\n",
        "# Print results\n",
        "print(\"parameters:\", grid_search.best_params_)\n",
        "print(\"Classification Report:\")\n",
        "print(cr)\n",
        "for N, accuracy in zip(N_values, top_n_accuracies):\n",
        "    print(f\"Top-{N} Accuracy Score: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.ticker import PercentFormatter\n",
        "# Plotting the top-N accuracy scores\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(N_values, top_n_accuracies, marker='o')\n",
        "plt.ylim(0, 1)  # Set y-axis limits between 0 and 1\n",
        "plt.xticks(N_values)\n",
        "plt.xlabel(\"Number of guesses\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "# plt.title(\"\")\n",
        "plt.gca().yaxis.set_major_formatter(PercentFormatter(xmax=1)) # %\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GJ6EMKhR7AD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoiVKFGi5QCz"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=target_names, yticklabels=target_names)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtKlO3ut7P3G"
      },
      "outputs": [],
      "source": [
        "#'C': [0.7, 1, 2, 5] 正则化\n",
        "# https://zhuanlan.zhihu.com/p/409250935"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLR\n"
      ],
      "metadata": {
        "id": "AwyXAXFQGI2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multinomial Logistic Regression"
      ],
      "metadata": {
        "id": "cODIivc5GOPA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i4vDv6CRGZmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import shuffle\n",
        "# data shift 数据 origial\n",
        "\n",
        "# Multinomial Logistic Regression  X,y 0.2 ；L2；10 fold across MFCC\n",
        "\n",
        "#X,y 0.2 ；L2；10 fold across MFCC\n",
        "\n",
        "multi_logreg = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\",max_iter=1000)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [ 1,10 ],\n",
        "    'penalty': ['l2']\n",
        "}\n",
        "\n",
        "# 10 fold across\n",
        "grid_search = GridSearchCV(multi_logreg, param_grid, cv=10, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "\n",
        "target_names = [f'Class {i}' for i in range(36)]\n",
        "\n",
        "# report\n",
        "cr = classification_report(y_test, y_pred, target_names=target_names)\n",
        "\n",
        "# Top-N accuracy score\n",
        "N_values = [1, 2, 3, 4, 5]  # You can add more N values if needed\n",
        "top_n_accuracies = [top_k_accuracy_score(y_test, best_model.predict_proba(X_test_scaled), k=N) for N in N_values]\n",
        "\n",
        "# Print top-N accuracy scores\n",
        "for N, accuracy in zip(N_values, top_n_accuracies):\n",
        "    print(f\"Top-{N} Accuracy Score: {accuracy:.4f}\")\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD5RlDbpJoQz",
        "outputId": "453fd700-8e39-432d-f3ca-dbefd1154a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 10, 'penalty': 'l2'}\n",
            "Top-1 Accuracy Score: 0.5748\n",
            "Top-2 Accuracy Score: 0.6633\n",
            "Top-3 Accuracy Score: 0.7211\n",
            "Top-4 Accuracy Score: 0.7653\n",
            "Top-5 Accuracy Score: 0.7959\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.43      0.75      0.55         8\n",
            "     Class 1       1.00      0.67      0.80         9\n",
            "     Class 2       0.60      0.33      0.43         9\n",
            "     Class 3       0.67      0.60      0.63        10\n",
            "     Class 4       0.43      0.67      0.52         9\n",
            "     Class 5       0.80      0.50      0.62         8\n",
            "     Class 6       0.50      0.67      0.57         9\n",
            "     Class 7       0.73      0.80      0.76        10\n",
            "     Class 8       0.60      0.90      0.72        10\n",
            "     Class 9       0.45      0.50      0.48        10\n",
            "    Class 10       0.40      0.57      0.47         7\n",
            "    Class 11       0.50      0.56      0.53         9\n",
            "    Class 12       0.67      0.50      0.57         8\n",
            "    Class 13       0.60      0.43      0.50         7\n",
            "    Class 14       0.67      0.44      0.53         9\n",
            "    Class 15       1.00      0.56      0.71         9\n",
            "    Class 16       0.29      0.25      0.27         8\n",
            "    Class 17       0.35      0.55      0.43        11\n",
            "    Class 18       0.40      0.29      0.33         7\n",
            "    Class 19       0.75      0.50      0.60         6\n",
            "    Class 20       0.67      0.80      0.73        10\n",
            "    Class 21       0.71      0.56      0.63         9\n",
            "    Class 22       0.43      0.67      0.52         9\n",
            "    Class 23       0.50      0.40      0.44        10\n",
            "    Class 24       1.00      0.67      0.80         9\n",
            "    Class 25       0.75      0.67      0.71         9\n",
            "    Class 26       0.75      0.60      0.67         5\n",
            "    Class 27       1.00      0.67      0.80         6\n",
            "    Class 28       0.54      0.88      0.67         8\n",
            "    Class 29       1.00      0.75      0.86         4\n",
            "    Class 30       0.50      0.17      0.25         6\n",
            "    Class 31       0.31      0.44      0.36         9\n",
            "    Class 32       0.50      0.38      0.43         8\n",
            "    Class 33       0.50      0.40      0.44         5\n",
            "    Class 34       0.67      0.86      0.75         7\n",
            "    Class 35       1.00      0.57      0.73         7\n",
            "\n",
            "    accuracy                           0.57       294\n",
            "   macro avg       0.63      0.57      0.58       294\n",
            "weighted avg       0.62      0.57      0.58       294\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHIFT DATA *3"
      ],
      "metadata": {
        "id": "6jINYfEoHFyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_logreg = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\",max_iter=1000)\n",
        "\n",
        "# parameters: {'C': 1, 'penalty': 'l2'}\n",
        "param_grid = {\n",
        "    'C': [ 1 ],\n",
        "    'penalty': ['l2']\n",
        "}\n",
        "\n",
        "# 10 fold across\n",
        "grid_search = GridSearchCV(multi_logreg, param_grid, cv=10, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train_extended, y_train_extended) # *3\n",
        "print(\"parameters:\", grid_search.best_params_)\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "\n",
        "target_names = [f'Class {i}' for i in range(36)]\n",
        "\n",
        "# report\n",
        "cr = classification_report(y_test, y_pred, target_names=target_names)\n",
        "\n",
        "# Top-N accuracy score\n",
        "N_values = [1, 2, 3, 4, 5]\n",
        "top_n_accuracies = [top_k_accuracy_score(y_test, best_model.predict_proba(X_test_scaled), k=N) for N in N_values]\n",
        "\n",
        "# Print top-N accuracy scores\n",
        "for N, accuracy in zip(N_values, top_n_accuracies):\n",
        "    print(f\"Top-{N} Accuracy Score: {accuracy:.4f}\")\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "mHds0cmDHE9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### random forest"
      ],
      "metadata": {
        "id": "pEYouzn6Jiwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pydot\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "from sklearn import metrics\n",
        "from openpyxl import load_workbook\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import KFold, cross_val_predict\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming you have loaded X_train_scaled, y_train, X_test_scaled, and y_test\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [ 5, 10],\n",
        "    'min_samples_leaf': [ 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Create and fit the Random Forest model using GridSearchCV\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(random_forest, param_grid, cv=10, n_jobs=-1) # 这个cv是什么？\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "best_random_forest = grid_search.best_estimator_\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "y_test_pred_probs = cross_val_predict(best_random_forest, X_test_scaled, y_test, cv=kf, method='predict_proba')\n",
        "\n",
        "#  top-N accuracy scores and generating the classification report\n",
        "N_values = [1, 2, 3, 4, 5]\n",
        "top_n_accuracies = []\n",
        "for N in N_values:\n",
        "    top_n_correct = 0\n",
        "    for true_label, pred_probs in zip(y_test, y_test_pred_probs):\n",
        "        top_n_indices = np.argsort(pred_probs)[::-1][:N]  # Indices of top-N classes\n",
        "        if true_label in top_n_indices:\n",
        "            top_n_correct += 1\n",
        "    top_n_accuracy = top_n_correct / len(y_test)\n",
        "    top_n_accuracies.append(top_n_accuracy)\n",
        "\n",
        "# Print the best hyperparameters found by GridSearchCV\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Print top-N accuracy scores\n",
        "for N, accuracy in zip(N_values, top_n_accuracies):\n",
        "    print(f\"Top-{N} Accuracy Score: {accuracy:.4f}\")\n",
        "\n",
        "# Generate classification report\n",
        "target_names = [f'Class {i}' for i in range(36)]\n",
        "y_test_pred = np.argmax(y_test_pred_probs, axis=1)\n",
        "cr = classification_report(y_test, y_test_pred, target_names=target_names)\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(cr)\n",
        "\n"
      ],
      "metadata": {
        "id": "V9PZvfOcTOWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "933f1e3e-ea00-4f3b-a37b-1368a1ac059d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters:\n",
            "{'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "Top-1 Accuracy Score: 0.2279\n",
            "Top-2 Accuracy Score: 0.3061\n",
            "Top-3 Accuracy Score: 0.3810\n",
            "Top-4 Accuracy Score: 0.4252\n",
            "Top-5 Accuracy Score: 0.4660\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.12      0.12      0.12         8\n",
            "     Class 1       0.18      0.22      0.20         9\n",
            "     Class 2       0.23      0.33      0.27         9\n",
            "     Class 3       0.29      0.50      0.37        10\n",
            "     Class 4       0.40      0.22      0.29         9\n",
            "     Class 5       0.00      0.00      0.00         8\n",
            "     Class 6       0.58      0.78      0.67         9\n",
            "     Class 7       0.12      0.20      0.15        10\n",
            "     Class 8       0.26      0.50      0.34        10\n",
            "     Class 9       0.38      0.50      0.43        10\n",
            "    Class 10       0.00      0.00      0.00         7\n",
            "    Class 11       0.29      0.22      0.25         9\n",
            "    Class 12       0.33      0.25      0.29         8\n",
            "    Class 13       0.00      0.00      0.00         7\n",
            "    Class 14       0.25      0.33      0.29         9\n",
            "    Class 15       0.00      0.00      0.00         9\n",
            "    Class 16       0.25      0.25      0.25         8\n",
            "    Class 17       0.11      0.18      0.14        11\n",
            "    Class 18       0.20      0.29      0.24         7\n",
            "    Class 19       0.00      0.00      0.00         6\n",
            "    Class 20       0.06      0.10      0.07        10\n",
            "    Class 21       0.25      0.22      0.24         9\n",
            "    Class 22       0.27      0.44      0.33         9\n",
            "    Class 23       0.25      0.20      0.22        10\n",
            "    Class 24       0.00      0.00      0.00         9\n",
            "    Class 25       0.13      0.22      0.17         9\n",
            "    Class 26       0.00      0.00      0.00         5\n",
            "    Class 27       0.67      0.33      0.44         6\n",
            "    Class 28       0.00      0.00      0.00         8\n",
            "    Class 29       0.00      0.00      0.00         4\n",
            "    Class 30       0.00      0.00      0.00         6\n",
            "    Class 31       0.29      0.22      0.25         9\n",
            "    Class 32       0.29      0.25      0.27         8\n",
            "    Class 33       0.00      0.00      0.00         5\n",
            "    Class 34       0.40      0.57      0.47         7\n",
            "    Class 35       0.25      0.14      0.18         7\n",
            "\n",
            "    accuracy                           0.23       294\n",
            "   macro avg       0.19      0.21      0.19       294\n",
            "weighted avg       0.20      0.23      0.21       294\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kDnuDzkRn-9A",
        "Il_vrf2a1-ro",
        "oTyev0xCIhWp"
      ],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMNQ5ndWcSbSrHHt4uKdtZ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}